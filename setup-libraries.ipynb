{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data with Spark HATS\n",
    "\n",
    "This Hands on Advanced Tutorial Session \n",
    "([HATS](http://lpc.fnal.gov/programs/schools-workshops/hats.shtml)) is\n",
    "presented by the LPC to demonstrate a CMS analysis using\n",
    "[Apache Spark](http://spark.apache.org/),\n",
    "[Spark-ROOT](https://github.com/diana-hep/spark-root),\n",
    "[Histogrammar](http://histogrammar.org/), and\n",
    "[MatplotLib](https://matplotlib.org/). After introducing Spark, students\n",
    "will learn the steps needed to perform a basic measurement\n",
    "of the Z-boson mass using CMS data recorded in 2016.\n",
    "\n",
    "*Note* - To perform any exercise, these notebooks must be open\n",
    "within [Jupyter](https://jupyter.org). GitHub has a very nice\n",
    "notebook renderer, but it is read-only and won't actually\n",
    "execute any code. Information on how to access Jupyter can\n",
    "be found in the [README](./README.md).\n",
    "\n",
    "\n",
    "\n",
    "Setup Instructions\n",
    "==========\n",
    "\n",
    "These instructions need to be run once to load the requisite libraries for the tutorial.\n",
    "\n",
    "Jupyter has the concept of _kernels_, which are independent execution environments. They don't\n",
    "even have to be Python, kernels for other languages exist as well.\n",
    "\n",
    "By loading a separate kernel for each project, we avoid the complication of different\n",
    "components/projects having weird interactions, ultimately helping reproducibility.\n",
    "\n",
    "We first produce a new virtualenv with the libraries we require, then we teach Jupyter\n",
    "about this new environment with the ipython executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "python2 -m virtualenv hats-spark\n",
    "source hats-spark/bin/activate\n",
    "HISTOGRAMMAR_PATH='git+https://github.com/histogrammar/histogrammar-python.git@1.0.x#egg=histogrammar'\n",
    "pip install ipykernel matplotlib numpy py4j $HISTOGRAMMAR_PATH\n",
    "ipython kernel install --user --name=hats-spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "=======\n",
    "\n",
    "If successful, you should see something similar to the following:\n",
    "\n",
    "```\n",
    "New python executable in /home/meloam/hats-template/hats-template/bin/python2\n",
    "Also creating executable in /home/meloam/hats-template/hats-template/bin/python\n",
    "Installing setuptools, pip, wheel...done.\n",
    "/home/meloam/hats-template/hats-template/bin/pip\n",
    "Collecting numpy==1.14.3\n",
    "  Using cached https://files.pythonhosted.org/packages/c0/e7/08f059a00367fd613e4f2875a16c70b6237268a1d6d166c6d36acada8301/numpy-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
    "<snip>\n",
    "Installed kernelspec hats-template in /home/meloam/.local/share/jupyter/kernels/hats-template\n",
    "```\n",
    "\n",
    "The new kernel you just made will then show up in the various Jupyter dropdowns, allowing you to use it for different notebooks. You can run the [pre-exercises](notebooks/00-preexercise.ipynb) to validate that your environment is properly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "* [Building blocks](notebooks/10-building-blocks.ipynb) - Introduction to the concepts of a Spark-based analysis\n",
    "* [Z-Peak with CMS data](notebooks/20-z-peak.ipynb) - Use Spark to plot the dimuon invariant mass peak\n",
    "\n",
    "## Built With\n",
    "\n",
    "* [Jupyter](http://jupyter.org/) - Interactive python notebook interface\n",
    "* [Apache Spark](http://spark.apache.org/) - Fast and general engine for large-scale data processing\n",
    "* [Spark-ROOT](https://github.com/diana-hep/spark-root) - Scala-based ROOT/IO interface to Spark\n",
    "* [Histogrammar](http://histogrammar.org/) - Functional histogramming framework, optimized for Spark\n",
    "* [MatplotLib](https://matplotlib.org/) - Python plotting library\n",
    "\n",
    "## Authors\n",
    "\n",
    "* **Andrew Melo** - http://lpc.fnal.gov/fellows/2017/Andrew_Melo.shtml\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "* The LPC Distinguished Researcher Program ([link](http://lpc.fnal.gov/fellows/2017.shtml)) - *Support for the author*\n",
    "* Advanced Computing Center for Research and Education (ACCRE) ([link](http://www.accre.vanderbilt.edu/)) - *Host facility and sysadmin support*\n",
    "* The Diana-HEP project ([link](http://diana-hep.org/)) - *Interoperability and compatibility libaries*\n",
    "* Vanderbilt Trans Institutional Program (TIPs) Award ([link](https://vanderbilt.edu/provost/occi/tips.php)) - *Big Data hardware seed funding*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
